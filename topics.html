<!DOCTYPE html>
<html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Neural Scene Representation and Neural Rendering -- Fall Semester 2025</title>
	<link rel="shortcut icon" href="favicon.ico">
	<link rel="stylesheet" type="text/css" href="data/gvv.css">
	<link rel="stylesheet" type="text/css" href="data/seminar.css">

	<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
	<script type="text/javascript">
		function togglePapers(o) {
			$(o).parents('table.topics tr').find('.paper').toggle();
			// $(o).parents('table.topics tr').find('.person').toggle();
		}

		function showAllPapers() {
			$('div.paper').show();
			$('div.container').show();
			$('div.comparison').show();
			$('a.showpapers').hide();
			$('a.hidepapers').show();
		}

		function hideAllPapers() {
			$('div.paper').hide();
			$('div.container').hide();
			$('div.comparison').hide();
			$('a.showpapers').show();
			$('a.hidepapers').hide();
		}
	</script>
</head>

<body>

	<div id="wrap">
		<div style="text-align: center">
			<a href="https://www.upenn.edu/"><img src="./data/penn.png" alt="Logos of UPenn" width="400"></a>
		</div>

		<h1 style="text-align: center;">Neural Scene Representation and Neural Rendering</h1>
		<h2 style="text-align: center;">Seminar – Fall Semester 2025</h2>
		<h3 style="text-align: center;">Instructor: <a href="https://lingjie0206.github.io/">Lingjie Liu</a>
		</h3>
		<h3 style="text-align: center;">TAs: <a href="https://czzzzh.github.io/">Chuhao Chen</a>, <a
			href="https://abhimanyusuthar.github.io/">Abhimanyu Suthar</a></h3>
		<br>

		<hr>
		<h2 style="text-align: center;">
			<a href="./index.html">Organization</a> &nbsp;|&nbsp;
			<b>Topics</b> &nbsp;|&nbsp; 
			<a href="./format.html">Format</a> &nbsp;|&nbsp;
			<a href="./resource.html">Resources</a>
		</h2>
		<hr>

		<table style="margin: 1em auto;">
			<tr>
				<td style="text-align:center; vertical-align:middle;"><video width="100%" playsinline=""
						autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="data/nerf.mp4" type="video/mp4">
					</video></td>
				<td style="text-align:center; vertical-align:middle;"><video width="80%" playsinline=""
						autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="data/more_results.mp4" type="video/mp4">
					</video></td>
			</tr>
			<tr>
				<td style="text-align:center;"><b>NeRF: Representing Scenes as Neural Radiance Fields for View
						Synthesis</b><br>ECCV, 2020</td>
				<td style="text-align:center;"><b>NeuS: Learning Neural
						Implicit
						Surfaces by Volume Rendering for Multi-view Reconstruction</b><br>NeurIPS,
					2021</td>
			</tr>
		</table>

		<br>



		<hr>
		<h2><a name="topics">Topics</a></h2>
		<hr>

		<br>

		<table class="topics" border="1">

			<tr>
				<th>Paper Presenting Schedule</th>
				<th width="160">Presentation</th>
			</tr>
			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Introduction</a></div>
				 <div class="paper">
						<div class="title"><a
								href="./01_intro_v2.pdf">slides (by Lingjie)
							</a></div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a onclick="togglePapers(this)"> <i>Sep 2</i></a></div>


				</td>
			</tr>
				
			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Introduction 2</a></div>
					<!-- <div class="paper">
						<div class="title"><a
								href="./slides/02_intro2.pdf">slides (by Lingjie)
							</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a onclick="togglePapers(this)"> <i>Sep 4</i></a></div>
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div class="topic"><a onclick="togglePapers(this)">Introduction 2 (Cont.)</a></div>
					<div class="paper">
							<div class="title"><a
								href="./slides/03_intro3.pdf">slides (by Lingjie)
							</a></div>
					</div>
					<div>
						<div class="title"><a
								href="https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_MonoNeRF_Learning_a_Generalizable_Dynamic_Radiance_Field_from_Monocular_Videos_ICCV_2023_paper.pdf">
								MonoNeRF: Learning a Generalizable Dynamic Radiance Field from Monocular Videos
							</a></div>
					</div>
					<div class="authors">Tian et al., ICCV 2023</div>
					<div><a
							href="https://docs.google.com/presentation/d/1X4Ut9Z5ZCziDdZim0_uSHAX2N1B3oKAxL5ekk9t_0Ik/edit#slide=id.p1"
							style="font-weight: bold;">slides
					</a>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 9</i></a></div>
					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Fengrui Tian</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="title"><a
							href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/">
							3D Gaussian Splatting for Real-Time Radiance Field Rendering
						</a></div>
					</div>
					<div class="authors">Kerbl et al., SIGGRAPH 2023 (Best Paper Award)</div>
					<div><a
							href="https://docs.google.com/presentation/d/1nrVRps6v2eS3APPRgGMgHEuJgFOW9hwv/edit"
							style="font-weight: bold;">slides
					</a>
					</div>
					<div>
						<div class="title"><a
							href="https://surfsplatting.github.io/">
							2D Gaussian Splatting for Geometrically Accurate Radiance Fields
						</a></div>
					</div>
					<div class="authors">Huang et al., SIGGRAPH 2024</div>
					<div><a
							href="https://docs.google.com/presentation/d/1V72VTceZklLDOnBoh826fmMHFIpqoQ3R/edit#slide=id.p1"
							style="font-weight: bold;">slides
					</a>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 11</i></a></div>
					<div class="person">
						<!-- <div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Daniel Alexander</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Wentinn Liao</div> -->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="topic"><a onclick="togglePapers(this)">Fast Rendering of Neural Radiance Fields
						</a></div>
						<div class="paper">
								<div class="title"><a
									href="./slides/04_fast_inferece.pdf">slides (by Lingjie)
								</a></div>
						</div>
						<div>
							<div class="title"><a
								href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/">
								Instant Neural Graphics Primitives with a Multiresolution Hash Encoding
							</a></div>
						</div>
						<div class="authors">Müller et al., SIGGRAPH 2022 (Best Paper Award)</div>
						<div><a
								href="https://docs.google.com/presentation/d/1JJd8wBh5RZNJHY6dJroEoBEbkCWowLrL35VtGHqN2mQ/edit#slide=id.p"
								style="font-weight: bold;">slides
						</a>
						</div>
						<div class="container">
							<div class="title"><a href="https://apchenstu.github.io/TensoRF/">
								TensoRF: Tensorial Radiance Fields</a></div>
							<div class="authors">Chen and Xu et al., ECCV 2022</div>
							<div class="title"><a href="https://apchenstu.github.io/FactorFields/"> 
								+ Factor Fields: A Unified Framework for Neural Fields and Beyond
								</a></div>
								<div class="authors">Chen et al., SIGGRAPH 2023</div>
							<div class="title"><a href="https://alexyu.net/plenoctrees/"> 
								+ PlenOctrees for Real-time Rendering of Neural Radiance Fields
								</a></div>
							<div class="authors">Yu et al., ICCV 2021 (Oral)</div>
							<div class="title"><a href="https://alexyu.net/plenoxels/"> 
								+ Plenoxels: Radiance Fields without Neural Networks
								</a></div>
							<div class="authors">Fridovich-Keil et al., CVPR 2022 (Oral)</div>
							<div><a
								href="https://docs.google.com/presentation/d/1GOI-3kzYmmeZOjDy8kEayE4lrsCJDJlT/edit?usp=drive_link&ouid=108046962876126744831&rtpof=true&sd=true"
								style="font-weight: bold;">slides
							</a>
							</div>
						</div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 16</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Hungju Wang</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Qiao Feng </div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="topic"><a onclick="togglePapers(this)">Fast Training of Neural Radiance Fields
						</a></div>
						<div class="paper">
								<div class="title"><a
									href="./slides/05_fast_training_Sept18.pdf">slides (by Lingjie)
								</a></div>
						</div>
						<div class="container">
							<div class="title"><a href="https://jonbarron.info/mipnerf/">
								Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</a></div>
							<div class="authors">Barron et al., ICCV 2021 (Oral, Best Paper Honorable Mention)</div>
							<div class="title"><a href="https://jonbarron.info/mipnerf360/"> 
								+ Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields
								</a></div>
								<div class="authors">Barron et al., CVPR 2022 (Oral Presentation)</div>
							<div class="title"><a href="https://jonbarron.info/zipnerf/"> 
								+ Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields
								</a></div>
							<div class="authors">Barron et al., ICCV 2023 (Oral Presentation, Best Paper Finalist)</div>
							<div><a
								href="https://docs.google.com/presentation/d/1HsXEaU-NzTcusCudkpKlEl8VnBaj9PvDOea-mW_pauI/edit?usp=drive_link"
								style="font-weight: bold;">slides
							</a>
							</div>
						</div>
						<div>
							<div class="title"><a
								href="https://niujinshuchong.github.io/mip-splatting/">
								Mip-Splatting: Alias-free 3D Gaussian Splatting
							</a></div>
						</div>
						<div class="authors">Yu et al., CVPR 2024 (Best Student Paper Finalist)</div>
						<div><a
								href="https://docs.google.com/presentation/d/1fcDpg4CMa2mHSjFgIvMOGZwJSpge770eFHtSDNJTd-s/edit?usp=sharing"
								style="font-weight: bold;">slides
							</a>
						</div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 18</i></a></div>

					<div class="person">
						<!-- <div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Matthew Leonard</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Yunzhou Song</div> -->
					</div>

				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="topic"><a onclick="togglePapers(this)">Unbounded Scene Modeling
						</a></div>
						<div class="paper">
								<div class="title"><a
									href="./slides/06_unbounded scenes_Sept23.pdf">slides (by Lingjie)
								</a></div>
						</div>
						<div class="container">
							<div class="title"><a href="https://creiser.github.io/merf/">
								MERF: Memory-Efficient Radiance Fields for Real-time View Synthesis in Unbounded Scenes</a></div>
							<div class="authors">Reiser et al., SIGGRAPH 2023</div>
							<div class="title"><a href="https://smerf-3d.github.io/"> 
								+ SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration
								</a></div>
								<div class="authors">Duckworth and Hedman et al., SIGGRAPH 2024 (Best Paper Honorable Mention)</div>
							<div><a
								href="https://docs.google.com/presentation/d/1qj4X1AEcWm-ojYJQRYSrpuIi-cF_Uzbn/edit?usp=drive_link&ouid=107579799759556819778&rtpof=true&sd=true"
								style="font-weight: bold;">slides
							</a>
							</div>
						</div>
						<div>
							<div class="title"><a
								href="https://city-super.github.io/gridnerf/">
								Grid-guided Neural Radiance Fields for Large Urban Scenes
							</a></div>
						</div>
						<div class="authors">Xu et al., CVPR 2023</div>
						<div><a
								href="https://docs.google.com/presentation/d/17XiEKW3qZxedYxLJvGedabXLmcJfIFhk/edit?usp=sharing&ouid=101714478856925599346&rtpof=true&sd=true"
								style="font-weight: bold;">slides
						</a>
						</div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 23</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Chen Wang</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Wentinn Liao</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="title"><a
							href="https://tobiasfshr.github.io/pub/4dgf/">
							Dynamic 3D Gaussian Fields for Urban Areas
						</a></div>
					</div>
					<div class="authors">Fischer et al., arXiv 2024</div>
					<div><a
							href="https://docs.google.com/presentation/d/1nA0u5u1QHlYOD2a48xIHFpbV55V6da9B/edit#slide=id.p1"
							style="font-weight: bold;">slides
					</a>
					</div>
					<div>
						<div class="title"><a
							href="https://alexyu.net/pixelnerf/">
							pixelNeRF Neural Radiance Fields from One or Few Images
						</a></div>
					</div>
					<div class="authors">Yu et al., CVPR 2021</div>
					<div><a
							href="https://docs.google.com/presentation/d/1XH4KOQ3q7v__zWlpaC6dPu5ZGugeD2lGuImLAIeFBZc/edit#slide=id.p"
							style="font-weight: bold;">slides
					</a>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 25</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Yiduo Hao</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Hungju Wang</div>
					</div> -->

				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="topic"><a onclick="togglePapers(this)">Guest Talk: Represent, Reconstruct and Generate the 4D Real World</a></div>
						<div class="paper">
								<div class="title"><a
									href="./slides/Sep_30.pdf">slides
								</a></div>
						</div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 30</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter: Jiahui Lei</div>
					</div> -->

				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="topic"><a onclick="togglePapers(this)">Generalization of Neural Fields
						</a></div>
						<div class="paper">
								<div class="title"><a
									href="./slides/Generalization_Oct2.pdf">slides (by Lingjie)
								</a></div>
						</div>
						<div>
							<div class="title"><a
								href="https://davidcharatan.com/pixelsplat/">
								PixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction
							</a></div>
						</div>
						<div class="authors">Charatan et al., CVPR 2024 (Oral)</div>
						<div><a
								href="https://docs.google.com/presentation/d/1BuVMYCWIHLjh_OTt9ienvWTvsFjY4LMO/edit"
								style="font-weight: bold;">slides
						</a></div>
						<div>
							<div class="title"><a
								href="https://yiconghong.me/LRM/">
								LRM: Large Reconstruction Model for Single Image to 3D
							</a></div>
						</div>
						<div class="authors">Hong et al., ICLR 2024 (Oral)</div>
						<div><a
								href="https://docs.google.com/presentation/d/1n6jpyQDPnGdysM6RIS0XmtGyHzVqZ2lA/edit?usp=drive_link&ouid=116881008652245717564&rtpof=true&sd=true"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 2</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Lee Milburn</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Fengtui Tian</div>
					</div> -->

				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="container">
							<div class="title"><a href="https://dreamfusion3d.github.io/">
								DreamFusion: Text-to-3d using 2D diffusion</a></div>
							<div class="authors">Poole et al., ICLR 2023</div>
							<div class="title"><a href="https://ml.cs.tsinghua.edu.cn/prolificdreamer/"> 
								+ ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation
								</a></div>
								<div class="authors">Wang et al. NeurIPS 2023 (Spotlight)</div>
							<div><a
								href="https://docs.google.com/presentation/d/1PBqBocC62HFYMVZm9LoE7J4kh9kxnAdY/edit#slide=id.p1"
								style="font-weight: bold;">slides
							</a>
							</div>
						</div>
						<div class="container">
							<div class="title"><a href="https://arxiv.org/abs/2404.07191">
								InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models</a></div>
							<div class="authors">Xu et al. arXiv 2024</div>
							<div class="title"><a href="https://me.kiui.moe/lgm/"> 
								+ LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation
								</a></div>
							<div class="authors">Tang et al. ECCV 2024 (Oral)</div>
							<div class="title"><a href="https://sudo-ai-3d.github.io/One2345plus_page/"> 
								+ One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion
								</a></div>
							<div class="authors">Liu et al. CVPR 2024</div>
							<div><a
								href="https://docs.google.com/presentation/d/1gD78mf_-iYqxMHGTOUteLcKU8h04o-T5/edit"
								style="font-weight: bold;">slides
							</a>
							</div>
						</div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 7</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Alex Radchenko</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Chen Wang</div>
					</div> -->

				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a>No Class</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 9</i></a></div>
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="topic"><a onclick="togglePapers(this)">Guest Talk: Towards Scalable and
							Knowledgeable Generative Intelligence</a></div>
						<div class="paper">
							<div class="title"><a
								href="./slides/Oct_14.pdf">slides
							</a></div>
						</div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 14</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter: Jiatao Gu</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="topic"><a onclick="togglePapers(this)">Guest Talk: Generative Embodied AI</a></div>
						<div class="paper">
							<div class="title"><a
								href="./slides/Oct_16.pdf">slides
							</a></div>
						</div>
						<div class="paper">
							<div class="title"><a
								href="https://drive.google.com/file/d/1SaO76--6Bw7SAmf8feQXMNLgrBsVdhu4/view?usp=drive_link">video
							</a></div>
						</div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 16</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter: Ruoshi Liu</div>
					</div> -->
				</td>
			</tr>


			<tr>
				<td>
					<div class="topic"><a>No Class</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 21 - Oct 23</i></a></div>
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div>
							<div class="title"><a
								href="https://bakedsdf.github.io/">
								BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis 
							</a></div>
						</div>
						<div class="authors">Yariv et al., SIGGRAPH 2023</div>
						<div><a
								href="https://docs.google.com/presentation/d/1xcH2nYHzcipOFToQtBGibspM_N5G3Nr84ZPWL50ASaE/edit?usp=sharing"
								style="font-weight: bold;">slides
						</a></div>
						<div>
							<div class="title"><a
								href="https://szymanowiczs.github.io/splatter-image">
								Splatter Image: Ultra-Fast Single-View 3D Reconstruction
							</a></div>
						</div>
						<div class="authors">Szymanowicz et al., CVPR 2024</div>
						<div><a
								href="https://docs.google.com/presentation/d/1FYkXxOjzinromNnX_h3iPLJlfFC7zGWZGfQxwzoxTXI/edit"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 28</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Zainab Afolabi</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Erik Jagnandan</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div>
							<div class="title"><a
								href="https://nvlabs.github.io/eg3d/">
								EG3D: Efficient Geometry-aware 3D Generative Adversarial Networks
							</a></div>
						</div>
						<div class="authors">Chan et al., CVPR 2022</div>
						<div><a
								href="https://docs.google.com/presentation/d/16gK_FRdGQmTJzAsydG6BRvpT-mkGuF-r/edit?usp=drive_link&ouid=107579799759556819778&rtpof=true&sd=true"
								style="font-weight: bold;">slides
						</a></div>
						<div>
							<div class="title"><a
								href="https://snap-research.github.io/3dgp/">
								3D generation on ImageNet
							</a></div>
						</div>
						<div class="authors">Skorokhodov et al., ICLR 2023 (Oral)</div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 30</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Yihang Liu</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Matthew Leonard</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div>
							<div class="title"><a
								href="https://sarafridov.github.io/K-Planes/">
								K-Planes: Explicit Radiance Fields in Space, Time, and Appearance
							</a></div>
						</div>
						<div class="authors">Fridovich-Keil et al., CVPR 2024</div>
						<div><a
								href="https://docs.google.com/presentation/d/1qiMpjpgqIInRV9YOWVkCnLDiXg7V2GCc/edit?usp=drive_web&ouid=101671697877703922510&rtpof=true"
								style="font-weight: bold;">slides
						</a></div>
						<div>
							<div class="title"><a
								href="https://zju3dv.github.io/4k4d/">
								4K4D: Real-Time 4D View Synthesis at 4K Resolution
							</a></div>
						</div>
						<div class="authors">Xu et al., CVPR 2024</div>
						<div><a
								href="https://docs.google.com/presentation/d/1J9cr5HwqoqJtV_Uotw2t0XWf5GWkDsWOtMUJQa36_Dc/edit#slide=id.p1"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 4</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Linzhan Mou</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Albert Wang</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div>
							<div class="title"><a
								href="https://oasisyang.github.io/colmap-free-3dgs/">
								COLMAP-Free 3D Gaussian Splatting
							</a></div>
						</div>
						<div class="authors">Fu et al., CVPR 2024 (Highlight)</div>
						<div><a
								href="https://docs.google.com/presentation/d/1i3pq37sROUBUWvyyOUuqEkFJ5RocBYFy/edit?usp=drive_link&ouid=107579799759556819778&rtpof=true&sd=true"
								style="font-weight: bold;">slides
						</a></div>
						<div>
							<div class="title"><a
								href="https://cameronosmith.github.io/flowcam/">
								FlowCam: Training Generalizable 3D Radiance Fields without Camera Poses via Pixel-Aligned Scene Flow
							</a></div>
						</div>
						<div class="authors">Smith et al., NeurIPS 2023</div>
						<div><a
								href="https://docs.google.com/presentation/d/1a8IV-uYL3-CRm4NZmtQOMtIi3bb1rZmE0NDYs3FWoaU/edit?usp=sharing"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 6</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Boshu Lei</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Yunzhou Song</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div>
							<div class="title"><a
								href="https://haian-jin.github.io/TensoIR/">
								TensoIR: Tensorial Inverse Rendering
							</a></div>
						</div>
						<div class="authors">Jin et al., CVPR 2023 </div>
						<div><a
								href="https://docs.google.com/presentation/d/1WaE1wf0wY_hTXL8vH-HEdrjCUXmn2IXr/edit?usp=drive_link&ouid=101671697877703922510&rtpof=true&sd=true"
								style="font-weight: bold;">slides
						</a></div>
						<div>
							<div class="title"><a
								href="https://nju-3dv.github.io/projects/Relightable3DGaussian/">
								Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF Decomposition and Ray Tracing
							</a></div>
						</div>
						<div class="authors">Zhang et al., ECCV 2024</div>
						<div><a
								href="https://docs.google.com/presentation/d/1Pu1tIMgyA09akHJb2ebZbdI0V_PiXlEu/edit?usp=drive_link&ouid=101671697877703922510&rtpof=true&sd=true"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 11</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Yihang Liu</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Carlos Lopez Garces</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<div>
						<!-- <div class="title"><a href="https://shellguo.com/osf/">Object-Centric Neural Scene
								Rendering
							</a></div>
						<div class="authors">Guo et al.</div>
						<div class="venue">Arxiv 2020</div> -->
					</div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 13</i></a></div>

					<div class="person">
						<!-- <div class="label">Presenter: Rahul Aggarwal</div> -->
					</div>

				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div>
							<div class="title"><a
								href="https://xpandora.github.io/PhysGaussian/">
								PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics
							</a></div>
						</div>
						<div class="authors">Xie et al., CVPR 2024 </div>
						<div><a
								href="https://drive.google.com/file/d/1gGeaBZj0XEdCOJrCbwkM8JAJ7FygWxpO/view?usp=drive_link"
								style="font-weight: bold;">slides
						</a></div>
						<div>
							<div class="title"><a
								href="https://qingqing-zhao.github.io/PhysAvatar">
								PhysAvatar: Learning the Physics of Dressed 3D Avatars from Visual Observations
							</a></div>
						</div>
						<div class="authors">Zheng et al., ECCV 2024</div>
						<div><a
								href="https://docs.google.com/presentation/d/1_k2RcbFUvzqplg-dg6UspHeTvHZRWBXo/edit?usp=sharing&ouid=113422604223403238967&rtpof=true&sd=true"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 18</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Boshu Lei</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Xiangyu Han</div>
					</div> -->

				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div>
							<div class="title"><a
								href="https://instruct-nerf2nerf.github.io/">
								Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions
							</a></div>
						</div>
						<div class="authors">Haque et al., ICCV 2023 (Oral) </div>
						<div><a
								href="https://docs.google.com/presentation/d/1BHiMqLyq-L0b1B4OKii7GDN3meev_RXbf7kESAe1__Y/edit?usp=drive_link"
								style="font-weight: bold;">slides
						</a></div>
						<div>
							<div class="title"><a
								href="https://platonerf.github.io/">
								PlatoNeRF: 3D Reconstruction in Plato's Cave via Single-View Two-Bounce Lidar
							</a></div>
						</div>
						<div class="authors">Klinghoffer et al., CVPR 2024 (Oral)</div>
						<div><a
								href="https://docs.google.com/presentation/d/1sX4FnulJAS-G2l4aGqKvIjP-0k3zeX0W/edit?usp=drive_link&ouid=101671697877703922510&rtpof=true&sd=true"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 20</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Erik Jagnandan</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Yiduo Hao</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="container">
							<div class="title"><a href="https://www.lerf.io/">
								LERF: Language Embedded Radiance Fields</a></div>
							<div class="authors">Kerr et al. ICCV 2023 (Oral)</div>
							<div class="title"><a href="https://lerftogo.github.io/desktop.html"> 
								+ LERF-TOGO: Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping
								</a></div>
							<div class="authors">Rashid et al. CORL 2023 (Best Paper Finalist)</div>
							<div><a
								href="https://docs.google.com/presentation/d/1tRBL3_GDuE9qGwRL7H_bTHOaqR9JZYqqTOwepREeoRE/edit?usp=sharing"
								style="font-weight: bold;">slides
							</a>
							</div>
						</div>
						<div></div>
							<div class="title"><a
								href="https://lucidsim.github.io/">
								Learning Visual Parkour from Generated Images
							</a></div>
						</div>
						<div class="authors">Yu et al., CoRL 2024</div>
						<div><a
								href="https://docs.google.com/presentation/d/1dO53QrsaU47wcWxcEJ8RFJyWB9F2_dCUAqYE0UpxUvA/edit?usp=sharing"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 25</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: William Liang</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: William Liang</div>
					</div> -->

				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a>No Class</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 27</i></a></div>

					<div class="person">
						<!-- <div class="label">Presenter: Rahul Aggarwal</div> -->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a>No Class (Tentative)</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Dec 2</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Qiao Feng</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Linzhan Mou</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a>No Class (Tentative)</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Dec 4</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Carlos Lopez Garces</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Alex Radchenko</div>
					</div> -->

				</td>
			</tr>

		</table>

		<p>
			The following table lists all the topics and papers that will be discussed in the seminar. 
			Once every participant has submitted their choice of topics and papers, the previous list will be updated to show the presenter
			of each topic. Send us an email if you cannot access a paper for some reason.
		</p>

		<div style="text-align:center;">
			<p>
				Click on each topic to show the papers to be discussed or
				<a href="javascript:showAllPapers()" class="showpapers">show all papers</a><a
					href="javascript:hideAllPapers()" class="hidepapers" style="display: none;">hide all papers</a>.
			</p>
		</div>

		<!-- <table class="topics" border="1">

			<tr>
				<th>Topic and Papers</th>
			</tr>
				

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Fast Inference</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a
									href="https://bakedsdf.github.io/">BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis
								</a></div>
							<div class="authors">Yariv et al.</div>
							<div class="venue">SIGGRAPH 2023</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/">3D
									Gaussian Splatting for
									Real-Time Radiance Field Rendering
								</a></div>
							<div class="authors">Kerbl et al.</div>
							<div class="venue">SIGGRAPH 2023 (Best Paper Award)</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://surfsplatting.github.io/">
								2D Gaussian Splatting for Geometrically Accurate Radiance Fields
								</a></div>
							<div class="authors">Huang et al.</div>
							<div class="venue">SIGGRAPH 2024</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Fast Training</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://arxiv.org/abs/2201.05989">
								Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</a></div>
							<div class="authors">Müller et al.</div>
							<div class="venue">SIGGRAPH 2022 (Best Paper Award)</div>
						</div>
					</div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://apchenstu.github.io/TensoRF/">
								TensoRF: Tensorial Radiance Fields</a></div>
							<div class="authors">Chen and Xu et al.</div>
							<div class="venue">ECCV 2022</div>
							<div class="title"><a href="https://apchenstu.github.io/FactorFields/"> 
								+ Factor Fields: A Unified Framework for Neural Fields and Beyond
								</a></div>
							<div class="authors">Chen et al.</div>
							<div class="venue">SIGGRAPH 2023</div>
							<div class="title"><a href="https://alexyu.net/plenoctrees/"> 
								+ PlenOctrees for Real-time Rendering of Neural Radiance Fields
								</a></div>
							<div class="authors">Yu et al.</div>
							<div class="venue">ICCV 2021 (Oral)</div>
							<div class="title"><a href="https://alexyu.net/plenoxels/"> 
								+ Plenoxels: Radiance Fields without Neural Networks
								</a></div>
							<div class="authors">Fridovich-Keil et al.</div>
							<div class="venue">CVPR 2022 (Oral)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Antialiasing</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://jonbarron.info/mipnerf/">Mip-NeRF: A Multiscale Representation
								for Anti-Aliasing Neural Radiance Fields
								</a></div>
							<div class="authors">Barron et al.</div>
							<div class="venue">ICCV 2021 (Oral, Best Paper Honorable Mention)</div>
							<div class="title"><a href="https://jonbarron.info/mipnerf360/">
								+ Mip-NeRF 360: Unbounded
									Anti-Aliased Neural Radiance Fields
								</a></div>
							<div class="authors">Barron et al.</div>
							<div class="venue">CVPR 2022 (Oral Presentation)</div>

							<div class="title"><a href="https://jonbarron.info/zipnerf/">
								+ Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields
								</a></div>
							<div class="authors">Barron et al.</div>
							<div class="venue">ICCV 2023 (Oral Presentation, Best Paper Finalist)</div>
						</div>
						<div class="comparison">
							<strong> Mip-NeRF v.s. Mip-NeRF 360 v.s. Zip-NeRF</strong>:<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>Common</strong>: Address the aliasing artifacts of NeRF.<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>Mip-NeRF</strong>: Mitigates aliasing artifacts at different resolutions by replacing point sampling with Gaussian sampling.<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>Mip-NeRF 360</strong>: Extends Mip-NeRF to unbounded scenes using a non-linear scene parameterization to allocate appropriate capacity for foreground and background.<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>Zip-NeRF</strong>: Addresses z-aliasing artifacts from Mip-NeRF 360's resampling and adapts to an efficient grid representation using multisampling within a conical frustum.
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://niujinshuchong.github.io/mip-splatting/">
								Mip-Splatting: Alias-free 3D Gaussian Splatting
								</a></div>
							<div class="authors">Yu et al.</div>
							<div class="venue">CVPR 2024 (Best Student Paper Finalist)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Large (Unbounded) Scenes</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://arxiv.org/abs/2302.12249">MERF:
									Memory-Efficient Radiance Fields for Real-time View Synthesis in Unbounded Scenes
								</a></div>
							<div class="authors">Reiser et al.</div>
							<div class="venue">SIGGRAPH 2023</div>
							<div class="title"><a href="https://smerf-3d.github.io/">
								+ SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration
								</a></div>
							<div class="authors">Duckworth and Hedman et al.</div>
							<div class="venue">SIGGRAPH 2024 (Best Paper Honorable Mention)</div>
						</div>
						<div class="comparison">
							<strong>MERF v.s. SMERF</strong>:<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>Common</strong>: Use compact representation to achieve high-quality real-time volumetric rendering.<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>MERF</strong>: Proposed a combination of a low-resolution 3D grid and a set of higher-resolution 2D planes.<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>SMERF</strong>: Supports real-time rendering on mobile devices; dedicates each viewpoint a MERF for large scenes.
						</div>
					</div>
					
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://city-super.github.io/gridnerf/">
								Grid-guided Neural Radiance Fields for Large Urban Scenes
								</a></div>
							<div class="authors">Xu et al.</div>
							<div class="venue">CVPR 2023</div>
						</div>
					</div>

					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://tobiasfshr.github.io/pub/4dgf/">
								Dynamic 3D Gaussian Fields for Urban Areas
								</a></div>
							<div class="authors">Fischer et al.</div>
							<div class="venue">arXiv 2024</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Generalization</a></div>

					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://alexyu.net/pixelnerf/">
								pixelNeRF Neural Radiance Fields from One or Few Images</a></div>
							<div class="authors">Yu et al.</div>
							<div class="venue">CVPR 2021</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://davidcharatan.com/pixelsplat/">
								PixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction</a></div>
							<div class="authors">Charatan et al.</div>
							<div class="venue">CVPR 2024 (Oral)</div>
							<div class="disc">(infers a 3D Gaussian scene from two input views in a single forward pass.)						</div>
						</div>
						
						<div class="paper">
							<div class="title"><a href="https://yiconghong.me/LRM/">
								LRM: Large Reconstruction Model for Single Image to 3D</a></div>
							<div class="authors">Hong et al.</div>
							<div class="venue">ICLR 2024 (Oral)</div>
						</div>
					</div>
				</td>

				
			</tr>


			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">3D Generative Model</a></div>

					<div class="scontainer">
						<div class="paper">
							<div class="title">[Per-scene optimization: diffusion distillation]</a></div>
						</div>
					</div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://dreamfusion3d.github.io/">
								DreamFusion: Text-to-3d using 2D diffusion</a></div>
							<div class="authors">Poole et al.</div>
							<div class="venue">ICLR 2023</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://ml.cs.tsinghua.edu.cn/prolificdreamer/">
								+ ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation</a></div>
							<div class="authors">Wang et al.</div>
							<div class="venue">NeurIPS 2023 (Spotlight)</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title">[Single-view image → Multi-view image → 3D reconstruction]</a></div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://cat3d.github.io/">
								Cat3D: Create Anything in 3D with Multi-View Diffusion Models</a></div>
							<div class="authors">Gao et al.</div>
							<div class="venue">arXiv 2024</div>
						</div>
					</div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://arxiv.org/abs/2404.07191">
								InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models</a></div>
							<div class="authors">Xu et al.</div>
							<div class="venue">arXiv 2024</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://me.kiui.moe/lgm/">
								+ LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation</a></div>
							<div class="authors">Tang et al.</div>
							<div class="venue">ECCV 2024 (Oral)</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://sudo-ai-3d.github.io/One2345plus_page/">
								+ One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion</a></div>
							<div class="authors">Liu et al.</div>
							<div class="venue">CVPR 2024</div>
						</div>
					</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title">[Pose-free 3D Generation]</a></div>
						</div>
					</div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://totoro97.github.io/pf-lrm/">
								PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction</a></div>
							<div class="authors">Wang et al.</div>
							<div class="venue">arXiv 2024</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://chaoxu.xyz/sparp/">
								+ SpaRP: Fast 3D Object Reconstruction and Pose Estimation from Sparse Views</a></div>
							<div class="authors">Xu et al.</div>
							<div class="venue">ECCV 2024</div>
						</div>
						<div class="comparison">
							<strong>PF-LRM v.s. SpaRP</strong>:<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>Common</strong>: 3D reconstruction from sparse unknown-posed images.<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>PF-LRM</strong>: Explicit matching through pointcloud + differentiable PnP solver.<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>SpaRP</strong>: Distill stable diffusion model to predict NOCS images for camera pose estimation.
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title">[Native 3D Generation]</a></div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://szymanowiczs.github.io/splatter-image">
								Splatter Image: Ultra-Fast Single-View 3D Reconstruction</a></div>
							<div class="authors">Szymanowicz et al.</div>
							<div class="venue">CVPR 2024</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title">[Multi-view ImageNet]</a></div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://nvlabs.github.io/eg3d/">EG3D: Efficient Geometry-aware 3D Generative Adversarial Networks</a></div>
							<div class="authors">Chan et al.</div>
							<div class="venue">CVPR 2022</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://snap-research.github.io/3dgp/">
								3D generation on ImageNet</a></div>
							<div class="authors">Skorokhodov et al.</div>
							<div class="venue">ICLR 2023 (Oral)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Dynamic Scenes & Human</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://shape-of-motion.github.io/">Shape of Motion: 4D Reconstruction from a Single Video
								</a></div>
							<div class="authors">Wang et al.</div>
							<div class="venue">arXiv 2024</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://www.cis.upenn.edu/~leijh/projects/mosca/">
								+ MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion Scaffolds
							</a></div>
							<div class="authors">Li et al.</div>
							<div class="venue">arXiv 2024</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://sarafridov.github.io/K-Planes/">K-Planes: Explicit Radiance Fields in Space, Time, and Appearance</a></div>
							<div class="authors">Fridovich-Keil et al.</div>
							<div class="venue">CVPR 2023</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://zju3dv.github.io/4k4d/">4K4D: Real-Time 4D View Synthesis at 4K Resolution</a></div>
							<div class="authors">Xu et al.</div>
							<div class="venue">CVPR 2024</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Pose Estimation</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://oasisyang.github.io/colmap-free-3dgs/">
								COLMAP-Free 3D Gaussian Splatting
								</a></div>
							<div class="authors">Fu et al.</div>
							<div class="venue">CVPR 2024</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://cameronosmith.github.io/flowcam/">
								FlowCam: Training Generalizable 3D Radiance Fields without Camera Poses via Pixel-Aligned Scene Flow
								</a></div>
							<div class="authors">Smith et al.</div>
							<div class="venue">NeurIPS 2023</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Lighting</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://haian-jin.github.io/TensoIR/">
								TensoIR: Tensorial Inverse Rendering
								</a></div>
							<div class="authors">Jin et al.</div>
							<div class="venue">CVPR 2023</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://nju-3dv.github.io/projects/Relightable3DGaussian/">
								Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF Decomposition and Ray Tracing
								</a></div>
							<div class="authors">Zhang et al.</div>
							<div class="venue">ECCV 2024</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Physics Simulation</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://xpandora.github.io/PhysGaussian/">
								PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics
								</a></div>
							<div class="authors">Xie et al.</div>
							<div class="venue">CVPR 2024 (Highlight)</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://qingqing-zhao.github.io/PhysAvatar">
								PhysAvatar: Learning the Physics of Dressed 3D Avatars from Visual Observations
							</a></div>
							<div class="authors">Zheng et al.</div>
							<div class="venue">ECCV 2024</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Editing & Multi-modality</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://instruct-nerf2nerf.github.io/">
								Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions
								</a></div>
							<div class="authors">Haque et al.</div>
							<div class="venue">ICCV 2023 (Oral)</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://platonerf.github.io/">
								PlatoNeRF: 3D Reconstruction in Plato's Cave via Single-View Two-Bounce Lidar
								</a></div>
							<div class="authors">Klinghoffer et al.</div>
							<div class="venue">CVPR 2024 (Oral, Best Paper Award Finalist)</div>
						</div>
					</div>
				</td>
			</tr>
			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Robotics</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://www.lerf.io/">
								LERF: Language Embedded Radiance Fields
								</a></div>
							<div class="authors">Kerr et al.</div>
							<div class="venue">ICCV 2023 (Oral)</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://lerftogo.github.io/">
								+ LERF-TOGO: Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping
								</a></div>
							<div class="authors">Rashid et al.</div>
							<div class="venue">CORL 2023 (Best Paper Finalist)</div>
						</div>
						<div class="comparison">
							<strong>LERF v.s. LERF-TOGO</strong>: <br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>Common</strong>: Embed language embeddings into 3D scene representation.<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>LERF</strong>: Enables pixel-aligned zero-shot queries on the distilled 3D CLIP embedding.<br>
							&nbsp;&nbsp;&nbsp;&nbsp;<strong>LERF-TOGO</strong>: Extends LERF to task-oriented grasping by adding DINO feature grouping.
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://sizhe-li.github.io/publication/neural_jacobian_field/">
								Unifying 3D Representation and Control of Diverse Robots with a Single Camera
								</a></div>
							<div class="authors">Li et al.</div>
							<div class="venue">arXiv 2024</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Surface Reconstruction</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://lingjie0206.github.io/papers/NeuS/">
								NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction
								</a></div>
							<div class="authors">Wang et al.</div>
							<div class="venue">NeurIPS 2021</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://vcai.mpi-inf.mpg.de/projects/NeuS2/">
								+ NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-view Reconstruction
								</a></div>
							<div class="authors">Wang et al.</div>
							<div class="venue">ICCV 2023</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://niujinshuchong.github.io/gaussian-opacity-fields/">
								Gaussian Opacity Fields: Efficient and Compact Surface Reconstruction in Unbounded Scenes
								</a></div>
							<div class="authors">Yu et al.</div>
							<div class="venue">SIGGRAPH ASIA 2024</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Differentiable Mesh Extraction</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://www.arxiv.org/abs/2405.13745">
								NeurCross: A Self-Supervised Neural Approach for Representing Cross Fields in Quad Mesh Generation
								</a></div>
							<div class="authors">Dong et al.</div>
							<div class="venue">arXiv 2024</div>
						</div>
						<div class="paper">
							<div class="title"><a href="https://research.nvidia.com/labs/toronto-ai/flexicubes/">
								Flexible Isosurface Extraction for Gradient-Based Mesh Optimization
								</a></div>
							<div class="authors">Shen et al.</div>
							<div class="venue">SIGGRAPH 2023</div>
						</div>
					</div>
				</td>
			</tr>

			

		</table> -->
	</div>

	<div id="footer">
		The website template and its content refer directly to <a
			href="https://vcai.mpi-inf.mpg.de/teaching/vcai_seminar_2023/index.html">MPII summer seminar</a> <br>
	</div>

</body>

</html>
