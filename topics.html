<!DOCTYPE html>
<html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Neural Scene Representation and Neural Rendering -- Fall Semester 2025</title>
	<link rel="shortcut icon" href="favicon.ico">
	<link rel="stylesheet" type="text/css" href="data/gvv.css">
	<link rel="stylesheet" type="text/css" href="data/seminar.css">

	<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
	<script type="text/javascript">
		function togglePapers(o) {
			$(o).parents('table.topics tr').find('.paper').toggle();
			// $(o).parents('table.topics tr').find('.person').toggle();
		}

		function showAllPapers() {
			$('div.paper').show();
			$('div.container').show();
			$('div.comparison').show();
			$('a.showpapers').hide();
			$('a.hidepapers').show();
		}

		function hideAllPapers() {
			$('div.paper').hide();
			$('div.container').hide();
			$('div.comparison').hide();
			$('a.showpapers').show();
			$('a.hidepapers').hide();
		}
	</script>
</head>

<body>

	<div id="wrap">
		<div style="text-align: center">
			<a href="https://www.upenn.edu/"><img src="./data/penn.png" alt="Logos of UPenn" width="400"></a>
		</div>

		<h1 style="text-align: center;">Neural Scene Representation and Neural Rendering</h1>
		<h2 style="text-align: center;">Seminar – Fall Semester 2025</h2>
		<h3 style="text-align: center;">Instructor: <a href="https://lingjie0206.github.io/">Lingjie Liu</a>
		</h3>
		<h3 style="text-align: center;">TAs: <a href="https://czzzzh.github.io/">Chuhao Chen</a>, <a
			href="https://abhimanyusuthar.github.io/">Abhimanyu Suthar</a></h3>
		<br>

		<hr>
		<h2 style="text-align: center;">
			<a href="./index.html">Organization</a> &nbsp;|&nbsp;
			<b>Topics</b> &nbsp;|&nbsp; 
			<a href="./format.html">Format</a> &nbsp;|&nbsp;
			<a href="./resource.html">Resources</a>
		</h2>
		<hr>

		<table style="margin: 1em auto;">
			<tr>
				<td style="text-align:center; vertical-align:middle;"><video width="100%" playsinline=""
						autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="data/nerf.mp4" type="video/mp4">
					</video></td>
				<td style="text-align:center; vertical-align:middle;"><video width="80%" playsinline=""
						autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="data/more_results.mp4" type="video/mp4">
					</video></td>
			</tr>
			<tr>
				<td style="text-align:center;"><b>NeRF: Representing Scenes as Neural Radiance Fields for View
						Synthesis</b><br>ECCV, 2020</td>
				<td style="text-align:center;"><b>NeuS: Learning Neural
						Implicit
						Surfaces by Volume Rendering for Multi-view Reconstruction</b><br>NeurIPS,
					2021</td>
			</tr>
		</table>

		<br>



		<hr>
		<h2><a name="topics">Topics</a></h2>
		<hr>

		<br>

		<table class="topics" border="1">

			<tr>
				<th>Paper Presenting Schedule</th>
				<th width="160">Presentation</th>
			</tr>
			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Introduction</a></div>
				 <div class="paper">
						<div class="title"><a
								href="./slides/01_intro_v2.pdf">slides (by Lingjie)
							</a></div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a onclick="togglePapers(this)"> <i>Sep 2</i></a></div>


				</td>
			</tr>
				
			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Introduction 2</a></div>
					<div class="paper">
						<div class="title"><a
								href="./slides/02_intro2_v2.pdf">slides (by Lingjie)
							</a></div>
					</div>
				</td>

				<td align="center">
					<div class="date"><a onclick="togglePapers(this)"> <i>Sep 4</i></a></div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="container">
						<div class="title"><a href="https://humansensinglab.github.io/taming-3dgs/">
							Taming 3DGS: High-Quality Radiance Fields with Limited Resources</a></div>
						<div class="authors">Mallick, Goel et al. SIGGRAPH Asia 2024</div>
						<div class="title"><a href="https://dashgaussian.github.io/"> 
							+ DashGaussian: Optimizing 3D Gaussian Splatting in 200 Seconds
							</a></div>
						<div class="authors">Chen et al. CVPR 2025 (Highlight)</div>
						<div><a
							href="https://docs.google.com/presentation/d/1HbNmWMG78RgqtbHar7mJnepvDzbcFY58/edit?usp=drive_link&ouid=101671697877703922510&rtpof=true&sd=true"
							style="font-weight: bold;">slides
						</a>
						</div>
					</div>
					<div class="container">
						<div class="title"><a href="https://donydchen.github.io/mvsplat/">
							MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images </a></div>
						<div class="authors">Chen et al. ECCV 2024 (Oral)</div>
						<div class="title"><a href="https://www.robots.ox.ac.uk/~vgg/research/flash3d/"> 
							+ Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image
							</a></div>
						<div class="authors">Szymanowicz, Insafutdinov et al. 3DV 2025</div>
						<div><a
							href="https://docs.google.com/presentation/d/1WKJXQGXgithRjzNqOEi1umeUM3XMyea8/edit?usp=drive_link&ouid=101671697877703922510&rtpof=true&sd=true"
							style="font-weight: bold;">slides
						</a>
						</div>
					</div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 9</i></a></div>
					<div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Ningze Zhong</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Michael Jacob</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="container">
				    <div class="title"><a href="https://arxiv.org/abs/2503.10148">
				        3D Student Splatting and Scooping
				    </a></div>
				    <div class="authors">Zhu et al. CVPR 2025 (Oral, Best Paper Honourable Mention)</div>
				    <div class="title"><a hre	f="https://chinmay0301.github.io/vol3dgs/">
				        + Volumetrically Consistent 3D Gaussian Rasterization
				    </a></div>
				    <div class="authors">Talegaonkar et al. CVPR 2025 (Highlight)</div>
				</div>
					<div class="scontainer">
				    <div class="title"><a href="https://quark-3d.github.io/">
				        Quark: Real-time, High-resolution, and General Neural View Synthesis
				    </a></div>
				    <div class="authors">
				        Flynn, Broxton, Murmann et al. SIGGRAPH Asia 2024 (Best Paper Award)
				    </div> 
				</div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 11</i></a></div>
					<div class="person">
						 <div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Dixuan Lin
</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Quynh Anh Huynh</div> 
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="container">
				    <div class="title"><a href="https://europe.naverlabs.com/research/publications/dust3r-geometric-3d-vision-made-easy/">
				        DUSt3R: Geometric 3D Vision Made Easy
				    </a></div>
				    <div class="authors">Wang et al. CVPR 2024</div>
				    <div class="title"><a href="https://hengyiwang.github.io/projects/spanner">
				        + SPANN3R: 3D Gaussian Splatting for Large-Scale Neural Reconstruction in the Wild
				    </a></div>
				    <div class="authors">Wang et al. 3DV 2025</div>
				    <div class="title"><a href="https://fast3r-3d.github.io/">
				        + Fast3R: Fast and High-Quality 3D Gaussian Splatting for Radiance Fields
				    </a></div>
				    <div class="authors">Yang et al. CVPR 2025</div>
				</div>
					<div class="scontainer">
				    <div class="title"><a href="https://vggsfm.github.io/">
				        VGGSfM: Accurate, Fast, and Scalable Structure-from-Motion
				    </a></div>
				    <div class="authors">Wang et al. CVPR 2024 (Highlight)</div>
				</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 16</i></a></div>

					 <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Shubhan Pawar</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Samuel Chua </div>
					</div> 
				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://vgg-t.github.io/">
							VGGT: Visual Geometry Grounded Transformer
						</a></div>
						<div class="authors">Wang et al. CVPR 2025 (Best Paper Award)</div>
					</div>
					<div class="scontainer">
						<div class="title"><a href="https://yyfz.github.io/pi3/">
							π³: Scalable Permutation-Equivariant Visual Geometry Learning
						</a></div>
						<div class="authors">Wang, Zhou et al. arXiv 2025</div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 18</i></a></div>

					<div class="person">
						 <div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Siyu Li</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Nehir Sunar</div> 
					</div>

				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://haian-jin.github.io/projects/LVSM/">
							LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias
						</a></div>
						<div class="authors">Jin et al. ICLR 2025 (Oral)</div>
					</div>
					<div class="scontainer">
						<div class="title"><a href="https://microsoft.github.io/renderformer/">
							RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination
						</a></div>
						<div class="authors">Zeng et al. SIGGRAPH 2025</div>
					</div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 23</i></a></div>

					 <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Aileen Liao</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Zhaowen Gu</div>
					</div> 
				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
					<div class="title"><a href="https://meshformer3d.github.io/">
						MeshFormer: High-Quality Mesh Generation with 3D-Guided Reconstruction Model
					</a></div>
					<div class="authors">Liu, Zeng et al. NeurIPS 2024 (Oral)</div>
				</div>
				<div class="scontainer">
					<div class="title"><a href="https://microsoft.github.io/TRELLIS/">
						TRELLIS: Structured 3D Latents for Scalable and Versatile 3D Generation
					</a></div>
					<div class="authors">Xiang et al. CVPR 2025 (Highlight)</div>
				</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 25</i></a></div> 
					 <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Shubhan Pawar</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Daiyuan Li</div>
					</div>  
				</td>
			</tr>

			<tr>
				<td>
					<div class="container">
						<div class="title"><a href="https://arxiv.org/abs/2407.17470">
							SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency
						</a></div>
						<div class="authors">Xie et al. ICLR 2025</div>
						<div class="title"><a href="https://sv4d20.github.io/">
							+ SV4D 2.0: Enhancing Spatio-Temporal Consistency in Multi-View Video Diffusion for High-Quality 4D Generation
						</a></div>
						<div class="authors">Yao et al. ICCV 2025</div>
						<div class="title"><a href="https://cat-4d.github.io/">
							+ CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models
						</a></div>
						<div class="authors">Wu et al. CVPR 2025</div>
					</div> 
					<div class="scontainer">
						<div class="title"><a href="https://shape-of-motion.github.io/">
							MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion Scaffolds
						</a></div>
						<div class="authors">Lei et al. CVPR 2025 (Highlight)</div>
					</div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Sep 30</i></a></div>

					 <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Yuntian Ke</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Neel Shejwalkar</div>
					</div> 

				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://shape-of-motion.github.io/">
							Shape of Motion: 4D Reconstruction from a Single Video
						</a></div>
						<div class="authors">Wang, Ye, Gao, Zeng et al. ICCV 2025 (Highlight)</div>
					</div>
					<div class="scontainer">
						<div class="title"><a href="https://linzhanm.github.io/dimo/">
							DIMO: Diverse 3D Motion Generation for Arbitrary Objects
						</a></div>
						<div class="authors">Mou et al. ICCV 2025 (Highlight)</div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 2</i></a></div>

					 <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Sagnik Anupam</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Tianang Leng</div>
					</div> 

				</td>
			</tr>

			<tr>
				<td> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 7</i></a></div> 
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a>No Class</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 9</i></a></div>
				</td>
			</tr>

			<tr>
				<td> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 14</i></a></div> 
				</td>
			</tr>

			<tr>
				<td>
					<div class="container">
						<div class="title"><a href="https://zlicheng.com/spring_gaus/">
							Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians
						</a></div>
						<div class="authors">Zhong et al. ECCV 2024</div>
						<div class="title"><a href="https://jianghanxiao.github.io/phystwin-web/">
							+ PhysTwin: Physics-Informed Reconstruction and Simulation of Deformable Objects from Videos
						</a></div>
						<div class="authors">Jiang et al. ICCV 2025</div>
					</div>
					<div class="scontainer">
						<div class="title"><a href="https://czzzzh.github.io/Vid2Sim/">
							Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation
						</a></div>
						<div class="authors">Chen et al. CVPR 2025</div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 16</i></a></div>

					<div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Quynh Anh Huynh	</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Daiyuan Li</div>
					</div> 
				</td>
			</tr>


			<tr>
				<td>
					<div class="topic"><a>No Class</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 21 - Oct 23</i></a></div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://gaussiansplashing.github.io/">
							Gaussian Splashing: Unified Particles for Versatile Motion Synthesis and Rendering
						</a></div>
						<div class="authors">Feng, Feng et al. CVPR 2025</div>
					</div>
					<div class="container">
						<div class="title"><a href="https://supertan0204.github.io/physmotion_website/">
							PhysMotion: Physics-Grounded Dynamics From a Single Image
						</a></div>
						<div class="authors">Tan, Jiang, Li et al. arXiv 2024</div>
						<div class="title"><a href="https://kyleleey.github.io/WonderPlay/">
							+ WonderPlay: Dynamic 3D Scene Generation from a Single Image and Actions
						</a></div>
						<div class="authors">Li, Yu et al. ICCV 2025 (Highlight)</div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 28</i></a></div>

					 <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Steven Su</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Ningze Zhong</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://drsplat.github.io/">
							Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language Embedding Registration
						</a></div>
						<div class="authors">Kim, Kim et al. CVPR 2025 (Highlight)</div>
					</div>
					<div class="container">
						<div class="title"><a href="https://repo-sam.inria.fr/fungraph/hierarchical-3d-gaussians/">
							A Hierarchical 3D Gaussian Representation for Real-Time Rendering of Very Large Datasets
						</a></div>
						<div class="authors">Kerbl, Meuleman et al. SIGGRAPH 2024</div>
						<div class="title"><a href="https://repo-sam.inria.fr/nerphys/on-the-fly-nvs/">
							+ On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images
						</a></div>
						<div class="authors">Meuleman et al. SIGGRAPH 2025</div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Oct 30</i></a></div>

					<div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Zhaowen Gu</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Samuel Chua	</div>
					</div> 
				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://edexheim.github.io/mast3r-slam/">
							MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors
						</a></div>
						<div class="authors">Murai, Dexheimer et al. CVPR 2025 (Highlight)</div>
					</div>
					<div class="scontainer">
						<div class="title"><a href="https://gaussian-world-model.github.io/">
							GWM: Towards Scalable Gaussian World Models for Robotic Manipulation
						</a></div>
						<div class="authors">Lu	, Jia, Li et al. ICCV 2025</div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 4</i></a></div>

					<div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Neel Shejwalkar</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Albert Wang</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://chengine.github.io/splatnav/">
							Splat-Nav: Safe Real-Time Robot Navigation in Gaussian Splatting Maps
						</a></div>
						<div class="authors">Chen, Shorinwa et al. TRO 2025</div>
					</div>
					<div class="scontainer">
						<div class="title"><a href="https://arm4r.github.io/">
							Pre-training Auto-regressive Robotic Models with 4D Representations
						</a></div>
						<div class="authors">Niu, Sharama et al. ICML 2025</div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 6</i></a></div>

					<div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Sagnik Anupam</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Aileen Liao</div>
					</div> 
				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://arxiv.org/abs/2312.15406v2">
							Objects as volumes: A stochastic geometry view of opaque solids
						</a></div>
						<div class="authors">Miller et al. CVPR 2024</div>
					</div>
					<div class="scontainer">
						<div class="title"><a href="https://arxiv.org/abs/2411.17067">
							Geometry Field Splatting with Gaussian Surfels
						</a></div>
						<div class="authors">Jiang et al. CVPR 2025</div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 11</i></a></div>

					<div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Hanqi Su</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Nehir Sunar</div>
					</div> 
				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://sites.google.com/view/cast4">
							CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image
						</a></div>
						<div class="authors">Yao, Zhang et al. SIGGRAPH 2025 (Best Paper Award)</div>
					</div>
					<div class="container">
						<div class="title"><a href="https://vast-ai-research.github.io/HoloPart/">
							HoloPart: Generative 3D Part Amodal Segmentation
						</a></div>
						<div class="authors">Yang et al. arXiv 2025</div>
						<div class="title"><a href="https://research.nvidia.com/labs/toronto-ai/partfield-release/">
							+ PartField: Learning 3D Feature Fields for Part Segmentation and Beyond
						</a></div>
						<div class="authors">Liu, Uy et al. ICCV 2025</div>
					</div> 
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 13</i></a></div>

					<div class="person">
						<div style="margin-top: 5pt;"></div>
						 <div class="label">Presenter 1: Yuntian Ke</div>
						 <div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Michael Jacob</div> 
						 
					</div>

				</td>
			</tr>

			<tr>
				<td>
					<div class="scontainer">
						<div class="title"><a href="https://research.nvidia.com/labs/toronto-ai/GEN3C/">
							GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera Control
						</a></div>
						<div class="authors">Ren, Shen et al. CVPR 2025 (Highlight)</div>
					</div>
					<div class="scontainer">
						<div class="title"><a href="https://research.nvidia.com/labs/toronto-ai/difix3d/">
							Difix3D+: Improving 3D Reconstructions with Single-Step Diffusion Models
						</a></div>
						<div class="authors">Wu, Zhang et al. CVPR 2025 (Best Paper Honorable Mention)</div>
					</div> 	
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 18</i></a></div>

					<div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Tianang Leng</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Dixuan Lin</div>
					</div> 

				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div>
							<div class="title"><a
								href="https://instruct-nerf2nerf.github.io/">
								Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions
							</a></div>
						</div>
						<div class="authors">Haque et al., ICCV 2023 (Oral) </div>
						<div><a
								href="https://docs.google.com/presentation/d/1BHiMqLyq-L0b1B4OKii7GDN3meev_RXbf7kESAe1__Y/edit?usp=drive_link"
								style="font-weight: bold;">slides
						</a></div>
						<div>
							<div class="title"><a
								href="https://platonerf.github.io/">
								PlatoNeRF: 3D Reconstruction in Plato's Cave via Single-View Two-Bounce Lidar
							</a></div>
						</div>
						<div class="authors">Klinghoffer et al., CVPR 2024 (Oral)</div>
						<div><a
								href="https://docs.google.com/presentation/d/1sX4FnulJAS-G2l4aGqKvIjP-0k3zeX0W/edit?usp=drive_link&ouid=101671697877703922510&rtpof=true&sd=true"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 20</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Erik Jagnandan</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Yiduo Hao</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<!-- <div>
						<div class="container">
							<div class="title"><a href="https://www.lerf.io/">
								LERF: Language Embedded Radiance Fields</a></div>
							<div class="authors">Kerr et al. ICCV 2023 (Oral)</div>
							<div class="title"><a href="https://lerftogo.github.io/desktop.html"> 
								+ LERF-TOGO: Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping
								</a></div>
							<div class="authors">Rashid et al. CORL 2023 (Best Paper Finalist)</div>
							<div><a
								href="https://docs.google.com/presentation/d/1tRBL3_GDuE9qGwRL7H_bTHOaqR9JZYqqTOwepREeoRE/edit?usp=sharing"
								style="font-weight: bold;">slides
							</a>
							</div>
						</div>
						<div></div>
							<div class="title"><a
								href="https://lucidsim.github.io/">
								Learning Visual Parkour from Generated Images
							</a></div>
						</div>
						<div class="authors">Yu et al., CoRL 2024</div>
						<div><a
								href="https://docs.google.com/presentation/d/1dO53QrsaU47wcWxcEJ8RFJyWB9F2_dCUAqYE0UpxUvA/edit?usp=sharing"
								style="font-weight: bold;">slides
						</a></div>
					</div> -->
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 25</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: William Liang</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: William Liang</div>
					</div> -->

				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a>No Class</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Nov 27</i></a></div>

					<div class="person">
						<!-- <div class="label">Presenter: Rahul Aggarwal</div> -->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a>No Class (Tentative)</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Dec 2</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Qiao Feng</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Linzhan Mou</div>
					</div> -->
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a>No Class (Tentative)</a></div>
				</td>

				<td align="center">
					<div class="date"><a> <i>Dec 4</i></a></div>

					<!-- <div class="person">
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 1: Carlos Lopez Garces</div>
						<div style="margin-top: 5pt;"></div>
						<div class="label">Presenter 2: Alex Radchenko</div>
					</div> -->

				</td>
			</tr>

		</table>

		<p>
			The following table lists all the topics and papers that will be discussed in the seminar. 
			Once every participant has submitted their choice of topics and papers, the previous list will be updated to show the presenter
			of each topic. Send us an email if you cannot access a paper for some reason.
		</p>

		<div style="text-align:center;">
			<p>
				Click on each topic to show the papers to be discussed or
				<a href="javascript:showAllPapers()" class="showpapers">show all papers</a><a
					href="javascript:hideAllPapers()" class="hidepapers" style="display: none;">hide all papers</a>.
			</p>
		</div>

		<table class="topics" border="1">

			<tr>
				<th>Topic and Papers</th>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Fast Training</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://humansensinglab.github.io/taming-3dgs/">
								Taming 3DGS: High-Quality Radiance Fields with Limited Resources</a></div>
							<div class="authors">Mallick, Goel et al.</div>
							<div class="venue">SIGGRAPH Asia 2024</div>
							<div class="title"><a href="https://dashgaussian.github.io/"> 
								+ DashGaussian: Optimizing 3D Gaussian Splatting in 200 Seconds
								</a></div>
							<div class="authors">Chen et al.</div>
							<div class="venue">CVPR 2025 (Highlight)</div> 
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Generalisable 3D Reconstruction</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://donydchen.github.io/mvsplat/">
								MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images</a></div>
							<div class="authors">Chen et al.</div>
							<div class="venue">ECCV 2024 (Oral)</div>
							<div class="title"><a href="https://www.robots.ox.ac.uk/~vgg/research/flash3d/"> 
								+ Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image
								</a></div>
							<div class="authors">Szymanowicz, Insafutdinov et al.</div>
							<div class="venue">3DV 2025</div> 
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">High-quality Rendering</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://arxiv.org/abs/2503.10148/">
								3D Student Splatting and Scooping
								</a></div>
							<div class="authors">Zhu et al.</div>
							<div class="venue">CVPR 2025 (Oral, Best Paper Honorable Mention)</div>
							<div class="title"><a href="https://chinmay0301.github.io/vol3dgs/">
								+ Volumetrically Consistent 3D Gaussian Rasterization
								</a></div>
							<div class="authors">Talegaonkar et al.</div>
							<div class="venue">CVPR 2025 (Highlight)</div> 
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://quark-3d.github.io/">
								Quark: Real-time, High-resolution, and General Neural View Synthesis
								</a></div>
							<div class="authors">Flynn, Broxton, Murmann et al.</div>
							<div class="venue">SIGGRAPH Asia 2024 (Best Paper Award)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Fast Visual Geometry</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://europe.naverlabs.com/research/publications/dust3r-geometric-3d-vision-made-easy/">
								DUSt3R: Geometric 3D Vision Made Easy</a></div>
							<div class="authors">Wang et al.</div>
							<div class="venue">CVPR 2024</div>
							<div class="title"><a href="https://hengyiwang.github.io/projects/spanner">
								+ Spann3R: 3D Reconstruction with Spatial Memory</a></div>
							<div class="authors">Wang et al.</div>
							<div class="venue">3DV 2025</div>
							<div class="title"><a href="https://fast3r-3d.github.io/">
								+ Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass</a></div>
							<div class="authors">Yang et al.</div>
							<div class="venue">CVPR 2025</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://vggsfm.github.io/">
								VGGSfM: Visual Geometry Grounded Deep Structure From Motion</a></div>
							<div class="authors">Wang et al.</div>
							<div class="venue">CVPR 2024 (Highlight)</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://vgg-t.github.io/">
								VGGT: Visual Geometry Grounded Transformer</a></div>
							<div class="authors">Wang et al.</div>
							<div class="venue">CVPR 2025 (Best Paper Award)</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://yyfz.github.io/pi3/">
								Pi^3: Scalable Permutation-Equivariant Visual Geometry Learning</a></div>
							<div class="authors">Wang, Zhou et al.</div>
							<div class="venue">arXiv 2025</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Transformer-based Neural Rendering</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://haian-jin.github.io/projects/LVSM/">
								LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias</a></div>
							<div class="authors">Jin et al.</div>
							<div class="venue">ICLR 2025 (Oral)</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://microsoft.github.io/renderformer/">
								RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination</a></div>
							<div class="authors">Zeng et al.</div>
							<div class="venue">SIGGRAPH 2025</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">3D Generation</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://meshformer3d.github.io/">
								MeshFormer: High-Quality Mesh Generation with 3D-Guided Reconstruction Model
								</a></div>
							<div class="authors">Liu, Zeng et al.</div>
							<div class="venue">NeurIPS 2024 (Oral)</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://microsoft.github.io/TRELLIS/">
								TRELLIS: Structured 3D Latents for Scalable and Versatile 3D Generation
								</a></div>
							<div class="authors">Xiang et al.</div>
							<div class="venue">CVPR 2025 (Highlight)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">4D Reconstruction & Generation</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://arxiv.org/abs/2407.17470">
								SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency
								</a></div>
							<div class="authors">Xie et al.</div>
							<div class="venue">ICLR 2025</div>
							<div class="title"><a href="https://sv4d20.github.io/">
								+ SV4D 2.0: Enhancing Spatio-Temporal Consistency in Multi-View Video Diffusion for High-Quality 4D Generation
								</a></div>
							<div class="authors">Yao et al.</div>
							<div class="venue">ICCV 2025</div>
							<div class="title"><a href="https://cat-4d.github.io/">
								+ CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models
								</a></div>
							<div class="authors">Wu et al.</div>
							<div class="venue">CPPR 2025</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://jiahuilei.com/projects/mosca/">
								MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion Scaffolds
								</a></div>
							<div class="authors">Lei et al.</div>
							<div class="venue">CVPR 2025 (Highlight)</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://shape-of-motion.github.io/">
								Shape of Motion: 4D Reconstruction from a Single Video
								</a></div>
							<div class="authors">Wang, Ye, Gao, Zeng et al.</div>
							<div class="venue">ICCV 2025 (Highlight)</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://linzhanm.github.io/dimo/">
								DIMO: Diverse 3D Motion Generation for Arbitrary Objects
								</a></div>
							<div class="authors">Mou et al.</div>
							<div class="venue">ICCV 2025 (Highlight)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Physics-grounded Reconstruction & Generation</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://zlicheng.com/spring_gaus/">
								Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians
								</a></div>
							<div class="authors">Zhong et al.</div>
							<div class="venue">ECCV 2024</div>
							<div class="title"><a href="https://jianghanxiao.github.io/phystwin-web/">
								+ PhysTwin: Physics-Informed Reconstruction and Simulation of Deformable Objects from Videos
								</a></div>
							<div class="authors">Jiang et al.</div>
							<div class="venue">ICCV 2025</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://czzzzh.github.io/Vid2Sim/">
								Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation
								</a></div>
							<div class="authors">Chen et al.</div>
							<div class="venue">CVPR 2025</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://gaussiansplashing.github.io/">
								Gaussian Splashing: Unified Particles for Versatile Motion Synthesis and Rendering
								</a></div>
							<div class="authors">Feng, Feng et al.</div>
							<div class="venue">CVPR 2025</div>
						</div>
					</div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://supertan0204.github.io/physmotion_website/">
								PhysMotion: Physics-Grounded Dynamics From a Single Image
								</a></div>
							<div class="authors">Tan, Jiang, Li et al.</div>
							<div class="venue">arXiv 2024</div>
							<div class="title"><a href="https://kyleleey.github.io/WonderPlay/">
								+ WonderPlay: Dynamic 3D Scene Generation from a Single Image and Actions
								</a></div>
							<div class="authors">Li, Yu et al.</div>
							<div class="venue">ICCV 2025 (Highlight)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Multi-modality</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://drsplat.github.io/">
								Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language Embedding Registration
								</a></div>
							<div class="authors">Kim, Kim et al.</div>
							<div class="venue">CVPR 2025 (Highlight)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Large Scene Reconstruction</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://repo-sam.inria.fr/fungraph/hierarchical-3d-gaussians/">
								A Hierarchical 3D Gaussian Representation for Real-Time Rendering of Very Large Datasets
								</a></div>
							<div class="authors">Kerbl, Meuleman et al.</div>
							<div class="venue">SIGGRAPH 2024</div>
							<div class="title"><a href="https://repo-sam.inria.fr/nerphys/on-the-fly-nvs/">
								+ On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images
								</a></div>
							<div class="authors">Meuleman et al.</div>
							<div class="venue">SIGGRAPH 2025</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Robotics</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://edexheim.github.io/mast3r-slam/">
								MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors.
								</a></div>
							<div class="authors">Murai, Dexheimer et al.</div>
							<div class="venue">CVPR 2025 (Highlight & Best Demo Honorable Mention)</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://gaussian-world-model.github.io/">
								GWM: Towards Scalable Gaussian World Models for Robotic Manipulation
								</a></div>
							<div class="authors">Lu, Jia, Li et al.</div>
							<div class="venue">ICCV 2025</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://chengine.github.io/splatnav/">
								Splat-Nav: Safe Real-Time Robot Navigation in Gaussian Splatting Maps
								</a></div>
							<div class="authors">Chen, Shorinwa et al.</div>
							<div class="venue">TRO 2025</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://arm4r.github.io/">
								Pre-training Auto-regressive Robotic Models with 4D Representations
								</a></div>
							<div class="authors">Niu, Sharma et al.</div>
							<div class="venue">ICML 2025</div>
						</div>
					</div>
				</td>
			</tr>
			
			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Surface Reconstruction</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://arxiv.org/abs/2312.15406v2">
								Objects as Volumes: A Stochastic Geometry View of Opaque Solids
								</a></div>
							<div class="authors">Miller et al.</div>
							<div class="venue">CVPR 2024</div>
						</div>
					</div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://arxiv.org/abs/2411.17067">
								Geometry Field Splatting with Gaussian Surfels
								</a></div>
							<div class="authors">Jiang et al.</div>
							<div class="venue">CVPR 2025</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Scene Components Reconstruction</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://sites.google.com/view/cast4">
								CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image
								</a></div>
							<div class="authors">Yao, Zhang et al.</div>
							<div class="venue">SIGGRAPH 2025 (Best Paper Award)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Part Segmentation</a></div>
					<div class="container">
						<div class="paper">
							<div class="title"><a href="https://vast-ai-research.github.io/HoloPart/">
								HoloPart: Generative 3D Part Amodal Segmentation
								</a></div>
							<div class="authors">Yang et al.</div>
							<div class="venue">arXiv 2025</div>
							<div class="title"><a href="https://research.nvidia.com/labs/toronto-ai/partfield-release/">
								+ PartField: Learning 3D Feature Fields for Part Segmentation and Beyond
								</a></div>
							<div class="authors">Liu, Uy et al.</div>
							<div class="venue">ICCV 2025</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Video Generation</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://research.nvidia.com/labs/toronto-ai/GEN3C/">
								GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera Control
								</a></div>
							<div class="authors">Ren, Shen et al.</div>
							<div class="venue">CVPR 2025 (Highlight)</div>
						</div>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<div class="topic"><a onclick="togglePapers(this)">Diffusion-based 3D Reconstruction</a></div>
					<div class="scontainer">
						<div class="paper">
							<div class="title"><a href="https://research.nvidia.com/labs/toronto-ai/difix3d/">
								DIFIX3D+: Improving 3D Reconstructions with Single-Step Diffusion Models
								</a></div>
							<div class="authors">Wu, Zhang et al.</div>
							<div class="venue">CVPR 2025 (Best Paper Honorable Mention)</div>
						</div>
					</div>
				</td>
			</tr>
 
		</table>
	</div>

	<div id="footer">
		The website template and its content refer directly to <a
			href="https://vcai.mpi-inf.mpg.de/teaching/vcai_seminar_2023/index.html">MPII summer seminar</a> <br>
	</div>

</body>

</html>
